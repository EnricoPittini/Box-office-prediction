{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto per il corso \"Data and Web Mining\" 2020/21\n",
    "Enrico Pittini 877345 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo file si spiega brevemente la struttura del progetto. Il progetto consiste in vari file notebook python, vari file python e un file csv. Tutta l'esposizione del progetto è all'interno dei file notebook : negli altri file sono presenti funzioni e dati di supporto.\n",
    "\n",
    "L'ordine con cui leggere i file notebook è il seguente.\n",
    "1. Il primo notebook è \"Analisi\", dove si analizza il dataset. Si valuta quali features ha senso considerare e varie alternative sul come si possono lavorare. Tale notebook ha l'obiettivo di dare una descrizione di queste varie alternative, senza però andare effettivamente a valutarle. \n",
    "2. Il secondo notebook è \"InserimentoFeatures_BanNumCatData\". In questo notebook si lavorano ed inseriscono le prime features, ovvero quelle numeriche, categoriali e di tipo data. Si fa ciò procedendo in modo incrementale. Vengono costruiti e valutati vari modelli. Innanzitutto si costruisce un primo modello banale, che funge da lower bound dello score dei modelli. Successivamente vengono creati vari modelli per ogni diversa possibile alternativa di lavorazione delle varie features (tali alternative sono state presentate nel notebook \"Analisi\"). Seleziono le alternative e i modelli migliori sulla base dello score del cross validation. Alla fine di questo notebook dunque ho un dataset di features lavorate e trattate adeguatamente, che provengono dalle features numeriche, categoriali e di tipo data del dataset grezzo iniziale. Inoltre ho anche costruito il modello (migliore) su tale dataset. Le funzioni che uso per effettuare tutte queste diverse lavorazioni sono contenute all'interno del file python \"lavorazione_dataset_NumCatData.py\".\n",
    "2. Il terzo notebook è \"InserimentoFeatures_BanNumCatData\". In questo notebook si continua a lavorare ed inserire altre features, ovvero quelle insiemistiche e testuali. Si fa ciò procedendo in modo incrementale. Vengono creati vari modelli per ogni diversa possibile alternativa di lavorazione delle varie features (tali alternative sono state presentate nel notebook \"Analisi\"). Seleziono le alternative e i modelli migliori sulla base dello score del cross validation. Alla fine di questo notebook ho il dataset finale di features lavorate e trattate adeguatamente. Inoltre ho anche costruito il modello (migliore) su tale dataset. Le funzioni che uso per effettuare tutte queste diverse lavorazioni sono contenute all'interno del file python \"lavorazione_dataset_InsText.py\".\n",
    "4. Infine l'ultimo notebook è \"RaffinamentiFinali\", dove si fanno gli ultimi raffinamenti e si mostrano dataset e modello finale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiego brevemente il contenuto dei file non ancora citati.\n",
    "- Il file python \"valutazione_modelli.py\" contiene le funzioni usate per valutare i modelli\n",
    "- Il file csv \"similarity_vector.csv\" contiene la matrice delle similarità tra i film, con similarità che prende in considerazione solo la feature \"overview\". Nel notebook \"Analisi\" (e successivi) è spiegato quando e come è usata.\n",
    "- Il file python \"similarity_vector.py\" contiene il codice usato per generare la matrice di similarità contenuta in \"similarity_vector.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, è presente un unico file pdf : \"report.pdf\". Tale file contiene la spiegazione riassuntiva dell'esposizione del progetto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
